# Звіт: лабораторна робота №2

**Дисципліна:** Моделі та методі обчислювального інтелекту

**Тема:** Аналіз якості моделі бінарної класифікації

**Студент:** Чалий Сергій (КН-Н425, 13 в списку групи)

---

[Код моделі](./lab_2__smile_sad_faces_assignment.py)

---

## Висновки щодо якості навченої моделі
### Основні проблеми якості моделі:

#### 1. **Перенавчання (Overfitting)**
- **Симптоми**: Висока точність на тренувальних даних (0.999) при низькій точності на тестових
- **Причини**:
  - Недостатньо даних для навчання
  - Занадто складна архітектура для розміру датасету
  - Відсутність регуляризації

#### 2. **Недостатня генералізація**
- Модель запам'ятовує конкретні приклади замість вивчення загальних ознак
- Погана продуктивність на нових, невідомих даних

#### 3. **Дисбаланс даних**
- Можлива нерівна кількість зображень у класах "happy" і "sad"
- Модель може бути схильна до передбачення більш частого класу

## Гіпотези щодо причин недостатньої якості моделі

### 1. **Архітектурні проблеми**
- **Занадто великий Dense шар (512 нейронів)** створює велику кількість параметрів
- **Відсутність Dropout шарів** - немає механізмів регуляризації
- **Швидке зростання кількості фільтрів** (16→32→64) може призвести до переоптимізації

### 2. **Проблеми з даними**
- **Малий розмір датасету** - недостатньо прикладів для навчання складної моделі
- **Низька якість аугментації даних** - поточна аугментація може бути недостатньою
- **Відсутність валідаційного набору** для контролю перенавчання

### 3. **Гіперпараметри навчання**
- **Занадто агресивнийCallback** (зупинка при accuracy ≥ 0.999)
- **Недостатня кількість епох** для стабільного навчання
- **Невідповідний learning rate** (0.001 може бути занадто високим або низьким)

### 4. **Методологічні проблеми**
- **Відсутність cross-validation** для оцінки стабільності моделі
- **Неправильне розбиття даних** на train/test набори
- **Відсутність стратифікованого семплінгу**

## Чому висока точність (0.999) не завжди є ознакою якості?

### 1. **Перенавчання**
```
Тренувальна точність: 99.9% ✓
Тестова точність: 60-70% ✗
↳ Модель запам'ятала тренувальні дані, але не навчилася загальним закономірностям
```

### 2. **Витік даних (Data Leakage)**
- Можливе дублювання зображень між train і test наборами
- Схожі зображення в обох наборах штучно завищують точність

### 3. **Дисбаланс класів**
```python
# Приклад проблеми:
happy_images: 800 (80%)
sad_images: 200 (20%)
# Модель просто передбачає "happy" і отримує 80% точності
```

### 4. **Неправильна метрика**
- Accuracy може вводити в оману при дисбалансі класів
- Потрібні додаткові метрики: precision, recall, F1-score

## Чому точність тренування і тестування сильно відрізняються?

### 1. **Класичне перенавчання**
```
Епоха 1: train_acc=0.65, val_acc=0.63 ✓ Здорове навчання
Епоха 5: train_acc=0.95, val_acc=0.70 ⚠️ Початок перенавчання  
Епоха 10: train_acc=0.999, val_acc=0.65 ✗ Сильне перенавчання
```

### 2. **Недостатня регуляризація**
- Відсутність Dropout шарів
- Відсутність BatchNormalization
- Занадто великий розмір моделі відносно кількості даних

### 3. **Проблеми з даними**
- Тренувальні дані не репрезентативні для реального розподілу
- Різна якість/освітлення/кути зйомки між train і test


## Шляхи покращення моделі

### 1. **Архітектурні покращення**
A. Додавання регуляризації:
B. Використання Transfer Learning:

### 2. **Покращення навчання**
A. Оновлені callbacks:
B. Кращі гіперпараметри:

### 3. **Покращення роботи з даними**
A. Розширена аугментація:
B. Валідаційний набір:

### 4. **Метрики та моніторинг**
A. Комплексна оцінка:
B. Візуалізація навчання:

### 5. **Стратегії валідації**
A. K-Fold Cross Validation:

---

### Підсумок

Поточна модель демонструє класичну проблему перенавчання. Основними напрямками покращення є додавання регуляризації, покращення роботи з даними та використання більш складних архітектур через Transfer Learning. Впровадження запропонованих змін має значно покращити генералізаційну здатність моделі.
